{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from numpy import median\n",
    "import urllib\n",
    "import math\n",
    "import random\n",
    "import collections\n",
    "import string\n",
    "import csv\n",
    "import sys\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "import sklearn.metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading labeled data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseLabeledData(path):\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.split(',')\n",
    "            yield({\"asin\":line[0],\n",
    "                 \"question\":line[1],\n",
    "                 \"review\":line[2],\n",
    "                 \"answer\":line[3],\n",
    "                 \"relevance\":float(line[4])\n",
    "                })\n",
    "        \n",
    "\n",
    "print(\"Reading labeled data...\")\n",
    "data = list(parseLabeledData(\"C:/Users/Moi/Downloads/highestReviewData.csv\"))\n",
    "#data = parseLabeledData(\"/Users/Silvia/Desktop/New Data - Sheet1.csv\")\n",
    "asins = [d['asin'] for d in data]\n",
    "queries = [d['question'] for d in data]\n",
    "reviews = [d['review'] for d in data]\n",
    "answers = [d['answer'] for d in data]\n",
    "relevances = [d['relevance'] for d in data]\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading all reviews & all questions...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def parseAllQueries(path):\n",
    "    file = open(path, 'r')\n",
    "    dataList = defaultdict(lambda: [])\n",
    "    for line in file:\n",
    "        line = eval(line)\n",
    "        dataList[line[\"asin\"]].append(line)\n",
    "      \n",
    "    return dataList\n",
    "\n",
    "def parseAllReviews(path):\n",
    "    file = open(path, 'r')\n",
    "    dataList = defaultdict(lambda: [])\n",
    "    for line in file:\n",
    "        line = eval(line)\n",
    "        dataList[line[\"asin\"]].append(line)\n",
    "      \n",
    "    return dataList\n",
    "\n",
    "print(\"Reading all reviews & all questions...\")\n",
    "\n",
    "allReviews = parseAllReviews(\"C:/Users/Moi/Downloads/reviews.json\")\n",
    "allQuestions = parseAllQueries(\"C:/Users/Moi/Downloads/qa.json\")\n",
    "\n",
    "#allReviews = parseAllReviews(\"/Users/Silvia/Downloads/reviews.json\")\n",
    "#allQuestions = parseAllQueries(\"/Users/Silvia/Downloads/qa.json\")\n",
    "\n",
    "# do we have to remove questions that have no reviews or reviews that have no questions??\n",
    "docSet = []\n",
    "for entry in allReviews.values():\n",
    "    for review in entry:\n",
    "        docSet.append(review[\"reviewText\"])\n",
    "\n",
    "for entry in allQuestions.values():\n",
    "    for question in entry:\n",
    "        docSet.append(question[\"question\"])\n",
    "\n",
    "docLen = [len(d.split()) for d in docSet]\n",
    "avgdl = sum(docLen) / len(docLen)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countAllWords():\n",
    "    allWords = defaultdict(int)\n",
    "    englishStopWords = stopwords.words('english')\n",
    "    for r in allReviews.values():\n",
    "        for review in r:\n",
    "            review = review[\"reviewText\"]\n",
    "            exclude = set(string.punctuation)\n",
    "            review = ''.join(ch for ch in review if ch not in exclude)\n",
    "            for w in review.lower().split():\n",
    "                if w not in englishStopWords:\n",
    "                    allWords[w] += 1\n",
    "\n",
    "    for q in allQuestions.values():\n",
    "        for question in q:\n",
    "            question = question[\"question\"]\n",
    "            exclude = set(string.punctuation)\n",
    "            question = ''.join(ch for ch in question if ch not in exclude)\n",
    "            for w in question.lower().split():\n",
    "                if w not in englishStopWords:\n",
    "                    allWords[w] += 1\n",
    "    \n",
    "    \n",
    "    return allWords\n",
    "\n",
    "allWords = countAllWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "commonWords = sorted(allWords, key=lambda x: -allWords[x])[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordToIndex(term):\n",
    "    if term in commonWords:\n",
    "        return commonWords.index(term)\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagCache = {}\n",
    "\n",
    "def bagOfWords(document, length):\n",
    "    if (document, length) in bagCache:\n",
    "        return bagCache[(document, length)]\n",
    "    \n",
    "    bag = [0]*length\n",
    "    \n",
    "    exclude = set(string.punctuation)\n",
    "    doc = ''.join(ch for ch in document if ch not in exclude)\n",
    "    doc = doc.lower().split()\n",
    "    \n",
    "    for term in doc:\n",
    "        index = wordToIndex(term)\n",
    "        \n",
    "        if index >= 0 and index < length:\n",
    "            bag[index] = doc.count(term)\n",
    "            \n",
    "    bagCache[(document, length)] = bag\n",
    "    \n",
    "    return bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwiseProduct(review, question, length):\n",
    "    reviewBag = bagOfWords(review, length)\n",
    "    questionBag = bagOfWords(question, length)\n",
    "        \n",
    "    bagFeat = [0]*length\n",
    "    \n",
    "    for i in range(0, length):\n",
    "        bagFeat[i] = reviewBag[i] * questionBag[i]\n",
    "        \n",
    "    #for i in range(0, length):\n",
    "        #if reviewBag[i] > 0 or questionBag[i] > 0:\n",
    "            #print(commonWords[i], reviewBag[i], questionBag[i], bagFeat[i])\n",
    "        \n",
    "    return bagFeat        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(term, document):\n",
    "    count = collections.defaultdict(int)\n",
    "    exclude = set(string.punctuation)\n",
    "    document = ''.join(ch for ch in document if ch not in exclude)\n",
    "    for word in document.split():\n",
    "        count[word] += 1\n",
    "\n",
    "    return count[term]/(len(document.split()) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfDict = defaultdict(float)\n",
    "\n",
    "def idf(term):\n",
    "    term = term.lower()\n",
    "    if (term in idfDict):\n",
    "        return idfDict[term]\n",
    "\n",
    "    count = 0\n",
    "    for doc in docSet:\n",
    "        #exclude = set(string.punctuation)\n",
    "        #doc = ''.join(ch for ch in doc if ch not in exclude)\n",
    "        if term in doc.lower():\n",
    "            count += 1\n",
    "        \n",
    "    idfScore = math.log(1 + len(docSet) / (count+1))\n",
    "    idfDict[term] = idfScore\n",
    "    return idfScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "okapidict = {}\n",
    "\n",
    "def OkapiBM25(review, question, k1, b):\n",
    "    if ((review, question, k1, b) in okapidict):\n",
    "        return okapidict[review, question, k1, b]\n",
    "    \n",
    "    question = question.lower()\n",
    "    question = ''.join([c for c in question if not (c in string.punctuation)])\n",
    "    \n",
    "    score = 0\n",
    "    for q in question.split():\n",
    "        num = tf(q, review) * (k1 + 1)\n",
    "        den = tf(q, review) + k1 * (1 - b + b*len(review.split()) / avgdl) \n",
    "        score += idf(q) * num / den\n",
    "        \n",
    "    #print(score, review, question)\n",
    "    okapidict[review, question, k1, b] = score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfdict = {}\n",
    "\n",
    "def tfidf(document):\n",
    "    if (document in tfidfdict):\n",
    "        return tfidfdict[document]\n",
    "    \n",
    "    doc = document.lower()\n",
    "    doc = ''.join([c for c in doc if not (c in string.punctuation)])\n",
    "        \n",
    "    feat = collections.defaultdict(int)\n",
    "    for term in doc.split():\n",
    "        tfscore = tf(term, doc)\n",
    "        idfscore = idf(term)\n",
    "        feat[term] = tfscore * idfscore\n",
    "        \n",
    "    tfidfdict[document] = feat\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queryFeat is a feature vector for the query and reviewFeat is the feature vector for the review\n",
    "def cosineSimilarity(queryFeat, reviewFeat):\n",
    "    # Find the words the 2 dictionaries have in common\n",
    "    querySet = set(queryFeat.keys())\n",
    "    reviewSet = set(reviewFeat.keys())\n",
    "    allWords = querySet.union(reviewSet)\n",
    "    \n",
    "    # Find the cosine similarity\n",
    "    numerator = 0\n",
    "    mag1 = 0\n",
    "    mag2 = 0\n",
    "    for word in allWords:\n",
    "        numerator = numerator + queryFeat[word] * reviewFeat[word]\n",
    "        mag1 = mag1 + queryFeat[word]**2\n",
    "        mag2 = mag2 + reviewFeat[word]**2\n",
    "    if mag1 > 0 and mag2 > 0:\n",
    "        return (numerator/((mag1*mag2)**0.5))\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featForOnlyQuestion(question, length):\n",
    "    return ([1]+bagOfWords(question, length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featForQuestionAndRelevantReview(review, question, length = 1000):\n",
    "    feat = [1]\n",
    "    feat += pairwiseProduct(review, question, length)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(featList):\n",
    "    \n",
    "    max = 0\n",
    "    min = float('inf')\n",
    "    for feat in featList:\n",
    "        if feat > max: max = feat\n",
    "        if feat < min: min = feat        \n",
    "    \n",
    "    for i in range(0,len(featList)-1):\n",
    "        if (max - min) == 0: \n",
    "            max = 1\n",
    "            min = 0\n",
    "        featList[i] = (featList[i] - min) / (max - min)\n",
    "\n",
    "    return featList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y): \n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X, y)\n",
    "    \n",
    "    return lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(y, y_hat):\n",
    "    #print(sklearn.metrics.r2_score(y, y_hat))\n",
    "    \n",
    "    \n",
    "    accuracy = sklearn.metrics.accuracy_score(y, y_hat)\n",
    "    precision = sklearn.metrics.precision_score(y, y_hat)\n",
    "    recall = sklearn.metrics.recall_score(y, y_hat)\n",
    "    \n",
    "    return \"{0:.3f}, {1:.3f}, {2:.3f}\".format(accuracy, precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrain(elems, point):    \n",
    "    for elem in elems:\n",
    "        if (elem > point): yield 1\n",
    "        else: yield 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6655\n"
     ]
    }
   ],
   "source": [
    "random.seed(505)\n",
    "\n",
    "thresh = 0.3\n",
    "\n",
    "yesPoint = [(featForQuestionAndRelevantReview(d[\"review\"], d[\"question\"], 500), 1 if d[\"answer\"] == \"Y\" else 0, d[\"relevance\"])\n",
    "            for d, i in zip(data, range(0, len(data))) if d[\"answer\"] == \"Y\" and d[\"relevance\"] > thresh]\n",
    "noPoint  = [(featForQuestionAndRelevantReview(d[\"review\"], d[\"question\"], 500), 1 if d[\"answer\"] == \"Y\" else 0, d[\"relevance\"])\n",
    "            for d, i in zip(data, range(0, len(data))) if d[\"answer\"] == \"N\" and d[\"relevance\"] > thresh]\n",
    "\n",
    "#yesPoint = [(featForOnlyQuestion(d[\"question\"], 1000), 1 if d[\"answer\"] == \"Y\" else 0)\n",
    "#            for d in data if d[\"answer\"] == \"Y\" and d[\"relevance\"] > thresh]\n",
    "#noPoint  = [(featForOnlyQuestion(d[\"question\"], 1000), 1 if d[\"answer\"] == \"Y\" else 0)\n",
    "#            for d in data if d[\"answer\"] == \"N\" and d[\"relevance\"] > thresh]\n",
    "\n",
    "#yesPoint = [(featForOnlyQuestion(d[\"question\"], 2000)\n",
    "#             + [d[\"relevance\"]],\n",
    "#             1 if d[\"answer\"] == \"Y\" else 0)\n",
    "#            for d in data if d[\"answer\"] == \"Y\" and d[\"relevance\"] > thresh]\n",
    "#noPoint  = [(featForOnlyQuestion(d[\"question\"], 2000)\n",
    "#             + [d[\"relevance\"]],\n",
    "#             1 if d[\"answer\"] == \"Y\" else 0)\n",
    "#            for d in data if d[\"answer\"] == \"N\" and d[\"relevance\"] > thresh]\n",
    "\n",
    "#yesPoint = random.sample(yesPoint, len(noPoint))\n",
    "\n",
    "points = yesPoint + noPoint\n",
    "random.shuffle(points)\n",
    "\n",
    "X = [p[0] for p in points]\n",
    "y = [p[1] for p in points]\n",
    "\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4436 4436 2219 2219\n"
     ]
    }
   ],
   "source": [
    "X_train = X[:len(X)*2//3]\n",
    "y_train = y[:len(X)*2//3]\n",
    "\n",
    "X_test = X[len(X)*2//3:]\n",
    "y_test = y[len(X)*2//3:]\n",
    "\n",
    "#X_test = [featForQuestionAndRelevantReview(d[\"review\"], d[\"question\"]) for d in data]\n",
    "#y_test = [1 if d[\"answer\"] == \"Y\" else 0 for d in data]\n",
    "#i_test = list(range(0, len(data)))\n",
    "                                           \n",
    "print(len(X_train), len(y_train), len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73796 73796 74760 74760\n"
     ]
    }
   ],
   "source": [
    "random.seed(505)\n",
    "\n",
    "thresh = 0.0\n",
    "\n",
    "points = []\n",
    "\n",
    "i = 0\n",
    "qNum = 0\n",
    "while i < len(data):\n",
    "    \n",
    "    qReviews = []\n",
    "    qRelevances = []\n",
    "\n",
    "    question = data[i][\"question\"]\n",
    "    answer = data[i][\"answer\"]\n",
    "\n",
    "    while (i < len(data) and data[i][\"question\"] == question):        \n",
    "        if (data[i][\"relevance\"] > thresh):\n",
    "            qReviews += [data[i][\"review\"]]\n",
    "            qRelevances += [data[i][\"relevance\"]]\n",
    "        i += 1\n",
    "\n",
    "    if (len(qReviews) > 0):\n",
    "        for qReview, qRelevance in zip(qReviews, qRelevances):\n",
    "            points += [(\n",
    "                featForOnlyQuestion(question, 200) + featForQuestionAndRelevantReview(qReview, question, 200), \n",
    "                1 if answer == \"Y\" else 0,\n",
    "                qNum\n",
    "            )]\n",
    "    qNum += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train = [p[0] for p in points if p[2] % 2 == 0]\n",
    "y_train = [p[1] for p in points if p[2] % 2 == 0]\n",
    "\n",
    "X_test = [p[0] for p in points if p[2] % 2 == 1]\n",
    "y_test = [p[1] for p in points if p[2] % 2 == 1]\n",
    "\n",
    "print(len(X_train), len(y_train), len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict with one question and the most relevant review!\n",
      "0.5 :\t 0.718, 0.723, 0.959 \t 0.664, 0.692, 0.916\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Predict with one question and the most relevant review!\")\n",
    "\n",
    "y_hatTrain = [p[1] for p in lr.predict_proba(X_train)]\n",
    "y_hatTest  = [p[1] for p in lr.predict_proba(X_test)]\n",
    "\n",
    "#y_hatTrain = [p[1] for i, p in zip(i_train, lr.predict_proba(X_train)) if relevances[i] > thresh]\n",
    "#y_hatTest  = [p[1] for i, p in zip(i_test, lr.predict_proba(X_test))  if relevances[i] > thresh]\n",
    "\n",
    "for cutoff in range(10, 11):\n",
    "    y_hatTrain_c = list(constrain(y_hatTrain, cutoff / 20))\n",
    "    y_hatTest_c = list(constrain(y_hatTest, cutoff / 20))\n",
    "    #print(len(y_hatTest_c), len(y_hatTest), len(X_test), len(y_test))\n",
    "    train_string = test(y_train, y_hatTrain_c)\n",
    "    test_string = test(y_test, y_hatTest_c)\n",
    "\n",
    "    print(cutoff / 20, \":\\t\", train_string, \"\\t\", test_string)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3857342114246163\n",
      "0.732, 0.751, 0.957\n"
     ]
    }
   ],
   "source": [
    "confidence = [abs(y - 0.5)*2 for y in y_hatTest]\n",
    "med = numpy.median(confidence)\n",
    "\n",
    "print(med)\n",
    "\n",
    "y_hatTest_c = list(constrain(y_hatTest, cutoff / 20))\n",
    "\n",
    "y_test2 = [y for y, y_hat in zip(y_test, y_hatTest) if abs(y_hat-0.5)*2 > med]\n",
    "y_hatTest_c2 = [y_c for y_c, y_hat in zip(y_hatTest_c, y_hatTest) if abs(y_hat-0.5)*2 > med]\n",
    "\n",
    "print(test(y_test2, y_hatTest_c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featForQuestionAndReviews(reviews, relevances, question, length):    \n",
    "    feat = [1]\n",
    "    \n",
    "    reviewBag = [0]*length\n",
    "    \n",
    "    relevances = [r for r in relevances]\n",
    "    \n",
    "    #totalRelevance = sum(relevances)\n",
    "    \n",
    "    med = numpy.median(relevances)\n",
    "    \n",
    "    thresh = 0.5\n",
    "    count = 0\n",
    "    for (review, relevance) in zip(reviews, relevances):\n",
    "        if relevance >= thresh or relevance >= med:\n",
    "            count += 1\n",
    "    \n",
    "    for (review, relevance) in zip(reviews, relevances):\n",
    "        if (relevance >= thresh or relevance >= med):\n",
    "            bow = bagOfWords(review, length)\n",
    "            reviewBag = [x + y * (relevance) / count for x, y in zip(reviewBag, bow)]\n",
    "            \n",
    "\n",
    "    questionBag = bagOfWords(question, length)\n",
    "    \n",
    "    bagFeat = [0]*length\n",
    "    \n",
    "    for i in range(0, length):\n",
    "        bagFeat[i] = questionBag[i] * reviewBag[i]\n",
    "        \n",
    "    cos = sum(bagFeat)\n",
    "    \n",
    "\n",
    "    feat += questionBag\n",
    "    feat += [cos]\n",
    "    feat += reviewBag\n",
    "    \n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8280\n"
     ]
    }
   ],
   "source": [
    "random.seed(15)\n",
    "\n",
    "thresh = 0.0\n",
    "\n",
    "points = []\n",
    "\n",
    "i = 0\n",
    "while i < len(data):\n",
    "\n",
    "    qReviews = []\n",
    "    qRelevances = []\n",
    "\n",
    "    question = data[i][\"question\"]\n",
    "    answer = data[i][\"answer\"]\n",
    "\n",
    "    while (i < len(data) and data[i][\"question\"] == question):        \n",
    "        if (data[i][\"relevance\"] > thresh):\n",
    "            qReviews += [data[i][\"review\"]]\n",
    "            qRelevances += [data[i][\"relevance\"]]\n",
    "        i += 1\n",
    "\n",
    "    if (len(qReviews) > 0):\n",
    "\n",
    "        featureVector = [([1] + [cosineSimilarity(tfidf(qReviews[0]), tfidf(question))], 1 if answer == \"Y\" else 0)]\n",
    "\n",
    "\n",
    "        #featureVector = [(featForQuestionAndReviews(qReviews, qRelevances, question, 200), 1 if answer == \"Y\" else 0)]\n",
    "        #for _ in range(0, len(qReviews)):\n",
    "        points += featureVector\n",
    "\n",
    "#yesPoint = [(featForQuestionAndReviews(d[\"review\"], d[\"question\"]), 1 if d[\"answer\"] == \"Y\" else 0, i)\n",
    "#            for d, i in zip(data, range(0, len(data))) if d[\"answer\"] == \"Y\" and d[\"relevance\"] > 0.5]\n",
    "#noPoint  = [(featForQuestionAndReviews(d[\"review\"], d[\"question\"]), 1 if d[\"answer\"] == \"Y\" else 0, i)\n",
    "#            for d, i in zip(data, range(0, len(data))) if d[\"answer\"] == \"N\" and d[\"relevance\"] > 0.5]\n",
    "\n",
    "#yesPoint = random.sample(yesPoint, len(noPoint))\n",
    "\n",
    "random.shuffle(points)\n",
    "\n",
    "X = [p[0] for p in points]\n",
    "y = [p[1] for p in points]\n",
    "\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4140 4140 4140 4140\n"
     ]
    }
   ],
   "source": [
    "X_train = X[:len(X)//2]\n",
    "y_train = y[:len(X)//2]\n",
    "\n",
    "X_test = X[len(X)//2:]\n",
    "y_test = y[len(X)//2:]\n",
    "\n",
    "print(len(X_train), len(y_train), len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict with one question and all the most relevant review!\n",
      "0.5 :\t 0.682, 0.682, 1.000 \t 0.686, 0.686, 1.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Predict with one question and all the most relevant review!\")\n",
    "\n",
    "y_hatTrain = [1 for p in lr.predict_proba(X_train)]\n",
    "y_hatTest  = [1 for p in lr.predict_proba(X_test)]\n",
    "\n",
    "for cutoff in range(10, 11):\n",
    "    y_hatTrain_c = list(constrain(y_hatTrain, cutoff / 20))\n",
    "    y_hatTest_c = list(constrain(y_hatTest, cutoff / 20))\n",
    "    train_string = test(y_train, y_hatTrain_c)\n",
    "    test_string = test(y_test, y_hatTest_c)\n",
    "\n",
    "    print(cutoff / 20, \":\\t\", train_string, \"\\t\", test_string)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "nan, 0.000, 0.000\n",
      "0.686, 0.686, 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36-64\\lib\\site-packages\\numpy\\lib\\function_base.py:1128: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "c:\\python36-64\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "confidence = [abs(y - 0.5)*2 for y in y_hatTest]\n",
    "med = numpy.median(confidence)\n",
    "\n",
    "print(med)\n",
    "\n",
    "y_hatTest_c = list(constrain(y_hatTest, cutoff / 20))\n",
    "\n",
    "y_test2 = [y for y, y_hat in zip(y_test, y_hatTest) if abs(y_hat-0.5)*2 > med]\n",
    "y_hatTest_c2 = [y_c for y_c, y_hat in zip(y_hatTest_c, y_hatTest) if abs(y_hat-0.5)*2 > med]\n",
    "\n",
    "print(test(y_test2, y_hatTest_c2))\n",
    "\n",
    "y_test2 = [y for y, y_hat in zip(y_test, y_hatTest) if abs(y_hat-0.5)*2 > .9]\n",
    "y_hatTest_c2 = [y_c for y_c, y_hat in zip(y_hatTest_c, y_hatTest) if abs(y_hat-0.5)*2 > .9]\n",
    "\n",
    "print(test(y_test2, y_hatTest_c2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.686, 0.686, 1.000\n",
      "0.686, 0.686, 1.000\n",
      "0.686, 0.686, 1.000\n",
      "0.686, 0.686, 1.000\n",
      "0.686, 0.686, 1.000\n",
      "0.686, 0.686, 1.000\n",
      "0.686, 0.686, 1.000\n",
      "0.686, 0.686, 1.000\n",
      "0.686, 0.686, 1.000\n",
      "0.686, 0.686, 1.000\n"
     ]
    }
   ],
   "source": [
    "y_test2 = [y for y, y_hat in zip(y_test, y_hatTest) if abs(y_hat-0.5)*2 > 0]\n",
    "y_hatTest_c2 = [y_c for y_c, y_hat in zip(y_hatTest_c, y_hatTest) if abs(y_hat-0.5)*2 > 0]\n",
    "print(test(y_test2, y_hatTest_c2))\n",
    "\n",
    "y_test2 = [y for y, y_hat in zip(y_test, y_hatTest) if abs(y_hat-0.5)*2 > .1]\n",
    "y_hatTest_c2 = [y_c for y_c, y_hat in zip(y_hatTest_c, y_hatTest) if abs(y_hat-0.5)*2 > .1]\n",
    "print(test(y_test2, y_hatTest_c2))\n",
    "\n",
    "y_test2 = [y for y, y_hat in zip(y_test, y_hatTest) if abs(y_hat-0.5)*2 > .2]\n",
    "y_hatTest_c2 = [y_c for y_c, y_hat in zip(y_hatTest_c, y_hatTest) if abs(y_hat-0.5)*2 > .2]\n",
    "print(test(y_test2, y_hatTest_c2))\n",
    "\n",
    "y_test2 = [y for y, y_hat in zip(y_test, y_hatTest) if abs(y_hat-0.5)*2 > .3]\n",
    "y_hatTest_c2 = [y_c for y_c, y_hat in zip(y_hatTest_c, y_hatTest) if abs(y_hat-0.5)*2 > .3]\n",
    "print(test(y_test2, y_hatTest_c2))\n",
    "\n",
    "y_test2 = [y for y, y_hat in zip(y_test, y_hatTest) if abs(y_hat-0.5)*2 > .4]\n",
    "y_hatTest_c2 = [y_c for y_c, y_hat in zip(y_hatTest_c, y_hatTest) if abs(y_hat-0.5)*2 > .4]\n",
    "print(test(y_test2, y_hatTest_c2))\n",
    "\n",
    "y_test2 = [y for y, y_hat in zip(y_test, y_hatTest) if abs(y_hat-0.5)*2 > .5]\n",
    "y_hatTest_c2 = [y_c for y_c, y_hat in zip(y_hatTest_c, y_hatTest) if abs(y_hat-0.5)*2 > .5]\n",
    "print(test(y_test2, y_hatTest_c2))\n",
    "\n",
    "y_test2 = [y for y, y_hat in zip(y_test, y_hatTest) if abs(y_hat-0.5)*2 > .6]\n",
    "y_hatTest_c2 = [y_c for y_c, y_hat in zip(y_hatTest_c, y_hatTest) if abs(y_hat-0.5)*2 > .6]\n",
    "print(test(y_test2, y_hatTest_c2))\n",
    "\n",
    "y_test2 = [y for y, y_hat in zip(y_test, y_hatTest) if abs(y_hat-0.5)*2 > .7]\n",
    "y_hatTest_c2 = [y_c for y_c, y_hat in zip(y_hatTest_c, y_hatTest) if abs(y_hat-0.5)*2 > .7]\n",
    "print(test(y_test2, y_hatTest_c2))\n",
    "\n",
    "y_test2 = [y for y, y_hat in zip(y_test, y_hatTest) if abs(y_hat-0.5)*2 > .8]\n",
    "y_hatTest_c2 = [y_c for y_c, y_hat in zip(y_hatTest_c, y_hatTest) if abs(y_hat-0.5)*2 > .8]\n",
    "print(test(y_test2, y_hatTest_c2))\n",
    "\n",
    "y_test2 = [y for y, y_hat in zip(y_test, y_hatTest) if abs(y_hat-0.5)*2 > .9]\n",
    "y_hatTest_c2 = [y_c for y_c, y_hat in zip(y_hatTest_c, y_hatTest) if abs(y_hat-0.5)*2 > .9]\n",
    "print(test(y_test2, y_hatTest_c2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
